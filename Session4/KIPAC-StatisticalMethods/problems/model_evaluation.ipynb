{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models with Bayesian Evidence and Information Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We'll be looking at some fake but realistic data and comparing how well different models do at describing it.\n",
    "\n",
    "It's a simple data set, just a list of numbers. Each one represents a measured distance between two different estimates of the center of a galaxy cluster: the location of the brightest galaxy and a centroid of the emissive, diffuse gas. The context here is that automated algorithms sometimes fail to chose the central galaxy correctly (because of image artifacts or other problems), whereas the gas centroid is more reliable but also more expensive to measure. Therefore, we'd like to use this data set to characterize the distribution of mis-centerings so that the galaxy-based centers can be used for large sample, with the resulting errors propagated forward through future processing, e.g., weak lensing estimates.\n",
    "\n",
    "Let's load up the data and have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = 'large'\n",
    "plt.rcParams['ytick.labelsize'] = 'large'\n",
    "%matplotlib inline\n",
    "# or %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.loadtxt('model_evaluation.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (6.0, 4.0)\n",
    "plt.hist(y, bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: evaluating a simple model\n",
    "\n",
    "First, let's fit and evaluate a simple model for the data. I propose the exponential distribution, but feel free to use a different guess.\n",
    "\n",
    "**Model 1:** $P(y|x_1) = \\frac{1}{x_1}e^{-y/x_1}$; $y\\geq0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a) Select a prior distribution for Model 1.\n",
    "\n",
    "Make sure it's a proper (normalizable) distribution. We don't want to deal with improper distributions when calculating the evidence later on.\n",
    "\n",
    "For e.g., to adopt a uniform prior, you could just use statements like the ones below, with appropriate implementation of later functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_lo =  # lower bound\n",
    "x1_hi =  # upper bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b) Implement likelihood, posterior, and predictive functions for Model 1.\n",
    "\n",
    "This code should get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log-likelihood function\n",
    "def lli1(x1):\n",
    "    # uses global 'y' variable where the data are stored\n",
    "    # x1 is a scalar\n",
    "    return np.sum(st.expon.logpdf( # complete\n",
    "\n",
    "# For convenience. This function can be called with a vector argument, unlike lli1.\n",
    "loglike1 = np.vectorize(lli1)\n",
    "\n",
    "# Log-posterior function. We'll use this with an MCMC sampler, so it should call the non-vectorized likelihood.\n",
    "def post1(p):\n",
    "    x1 = p[0]\n",
    "    # something to do with the prior here, setting the value of pr\n",
    "    like = lli1(x1)\n",
    "    return like + pr\n",
    "\n",
    "# Posterior-predictive density\n",
    "def postpredpdf1(yy, x1):\n",
    "    return st.expon.pdf( # complete\n",
    "\n",
    "# Perform posterior prediction\n",
    "def postpred1(n, x1):\n",
    "    # return n mock data points from the model\n",
    "    return st.expon.rvs( # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c) Fit Model 1.\n",
    "\n",
    "Code below will do parameter inference, look at the resulting Markov chains, remove burn-in, thin, and concatenate chains. Since this step isn't really the point of this problem, it's mostly given, but you'll still need to fill in a few pieces. Make sure you understand the format that the MCMC results are stored in (e.g. the `samples1` variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import emcee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the sampling problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example sampler setup\n",
    "nwalkers = 100\n",
    "ndim = 1 # number of parameters\n",
    "lnprob = post1\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob) # add e.g. threads=4 to speed things up with multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define starting points for each chain in the ensemble. Given a guess at the right answer, this code initializes them to be at the guess $\\pm1$%. For later, note that this array should have dimensions `Nwalkers` $\\times$ `Nparameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guess = # complete\n",
    "theta1_0 = np.array([[guess]*(1.0 + 0.01*np.random.rand(ndim)) for j in range(nwalkers)])\n",
    "theta1_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the sampler and look at the resulting chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler.run_mcmc(theta1_0, 1000)\n",
    "ens1 = sampler.chain\n",
    "plt.rcParams['figure.figsize'] = (12.0, 3.0)\n",
    "for j in range(nwalkers): plt.plot(ens1[j,:,0], 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove obvious burn-in and do some thinning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "burn = # complete\n",
    "thinby = # complete\n",
    "samples1 = ens1[:, burn:, :].reshape((-1, ndim))\n",
    "samples1 = samples1[range(0,samples1.shape[0],thinby),:]\n",
    "samples1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be useful for later to know the mean of the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postmean1 = np.mean(samples1[:,0])\n",
    "postmean1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1d) Visually compare the predictions of Model 1 with the data.\n",
    "\n",
    "First, let's just plot the posterior-mean model over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (6.0, 4.0)\n",
    "plt.hist(y, bins=50, normed=True)\n",
    "yy = np.arange(1000.)\n",
    "plt.plot(yy, postpredpdf1( # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare a random predicted data set from the posterior with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = # arbitrary posterior sample\n",
    "mock = postpred1( # complete\n",
    "plt.hist(y, bins=50)\n",
    "plt.hist(mock, bins=50, color=[1,0,0,0.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively, would you say the model is a good fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1e) Choose a simple test statistic and use it to compare the data with the posterior predictive distribution.\n",
    "\n",
    "Do this visually, as well as calculating the corresponding $p$-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example setup is for a test function of data only (no parameter dependence)\n",
    "def T(yy):\n",
    "    return # complete\n",
    "# compute T from draws from every posterior sample\n",
    "pp = np.array([T(postpred1(len(y), x1)) for x1 in samples1[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show a histogram of pp\n",
    "# compare that distribution with T(real data)\n",
    "# compute and report the p-value for T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the quantitative goodness-of-fit match your expectation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1f) Calculate the DIC for Model 1.\n",
    "\n",
    "Also compute the value of $p_D$. (Does it make sense?) We'll compare these to the corresponding values for a different model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute things\n",
    "pD1 = # complete\n",
    "DIC1 = # complete\n",
    "print pD1, DIC1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1g) Compute the evidence for Model 1.\n",
    "\n",
    "To do this, note that\n",
    "\n",
    "$P(D|H)=\\int P(D|\\theta,H) \\, P(\\theta|H) d\\theta$\n",
    "\n",
    "can be approximated by an average over samples from the prior\n",
    "\n",
    "$P(D|H) \\approx \\sum_{k=1}^m P(D|\\theta_k,H)$; $\\theta_k\\sim P(\\theta|H)$.\n",
    "\n",
    "This approach is not especially efficient or numerically stable in general (because the likelihood typically is large in only a small fraction of the prior volume), but it will do for this exercise.\n",
    "\n",
    "Draw a large number of samples ($m$) from the prior and use them to calculate the evidence. In fact, to avoid numerical over/underflows, we'll need to add a constant to the log-likelihoods before exponentiating them in the average (which of course means that we don't actually get the evidence out! This is another reason to prefer better methods that more stably produce the evidence or log-evidence). To compare evidences from 2 models, we'll of course need to add the *same* constant in each case. Nevertheless, it's worth putting together the machinery to do these calculations now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nmc = # suitable large number of draws from the prior\n",
    "x1_from_prior = # complete\n",
    "ll_from_prior1 = loglike1( # complete\n",
    "\n",
    "ev1 = # complete\n",
    "print ev1\n",
    "    \n",
    "# NB do not compare ev1 to the evidence for another model unless the same constant has been used to offset the\n",
    "# two log-likelihoods!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: evaluating a more complex model\n",
    "\n",
    "Choose a more complex model to compare to Model 1. I suggest incorporating another standard PDF (implemented in `scipy`) into the likelihood, with a parameter indicating the relative proportion of the two components, such that\n",
    "\n",
    "$P(y|\\theta_1,\\theta_2,f) = f\\,P_1(y|\\theta_1) + (1-f)\\,P_2(y|\\theta_2)$.\n",
    "\n",
    "But feel free to do something different if you like.\n",
    "\n",
    "Next, repeat the various fitting and evaluating steps that we did for Model 1 for this new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a) Specify Model 2, and a choose sensible prior distribution.\n",
    "\n",
    "If following the hint above, don't forget that $f$ is also a parameter of the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b) Implement likelihood, posterior, and predictive functions for Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log-likelihood function\n",
    "def lli2( # complete\n",
    "\n",
    "# For convenience. This function can be called with a vector argument, unlike lli2.\n",
    "loglike2 = np.vectorize(lli2)\n",
    "\n",
    "# Log-posterior function. We'll use this with an MCMC sampler, so it should call the non-vectorized likelihood.\n",
    "def post2(p):\n",
    "    # complete\n",
    "\n",
    "# Posterior-predictive density\n",
    "def postpredpdf2(yy, # complete\n",
    "\n",
    "# Perform posterior prediction\n",
    "def postpred2(n, f, # complete\n",
    "    # return n mock data points from the model\n",
    "    # if your model is built out of two components with relative proportions f and (1-f), you could do something like:\n",
    "    y1 = # complete - n draws from the first component\n",
    "    y2 = # complete - n draws from the second component\n",
    "    r = np.random.sample(n)\n",
    "    return np.concatenate((y1[np.where(r <= frac)], y2[np.where(r > frac)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c) Fit Model 2.\n",
    "\n",
    "The code above should still work, with relatively minor changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2d) Visually compare the predictions of Model 2 with the data.\n",
    "\n",
    "Do the same quantitative posterior predicive test as before, also. Does the new model fit the data better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2e) Compare the data with the posterior predictive distribution of your test statistic for Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2f) Calculate the DIC and $p_D$ for Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# complete\n",
    "print pD2, DIC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2g) Compute the evidence for Model 2.\n",
    "\n",
    "As before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a) Use the difference in DIC between models 1 and 2 to conclude something about the relative fitness of the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print DIC2 - DIC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b) Use the evidence ratio of the two models to conclude something about their relative probability.\n",
    "\n",
    "You'll need to re-calculate the evidences in this step. As before, the log-likelihoods will need to be offset by a constant to avoid numerical over/underflows, but of course the *same* offset needs to be applied to each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# complete\n",
    "print logevidence1, logevidence2, logevidence2-logevidence1, np.exp(logevidence2-logevidence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge problem\n",
    "\n",
    "Use `emcee`'s parallel tempering functionality to calculate the log-evidences for the two models above (see the [documentation](http://dan.iel.fm/emcee/current/user/pt/)). Compare the difference in log-evidence with what you found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mega-Challenge problem\n",
    "\n",
    "[This notebook](challenge_thermo_integ.ipynb) provides the opportunity to delve into thermodynamic integration as a method of computing the evidence (this is what `emcee` does in the challenge problem above) in more detail, to see how and why it works."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
